{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "88c48cc1"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/ClimateProject/NORESM2_LM_full.zip'\n",
        "extraction_dir = '/tmp/NORESM2_LM_full'\n",
        "\n",
        "os.makedirs(extraction_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Extracting '{zip_file_path}' to '{extraction_dir}'...\")\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_dir)\n",
        "print(\"Extraction complete.\")\n",
        "print(f\"Contents of '{extraction_dir}':\")\n",
        "print(os.listdir(extraction_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13a0a9ba"
      },
      "source": [
        "print(f\"Listing contents of '{extraction_dir}' recursively:\")\n",
        "for root, dirs, files in os.walk(extraction_dir):\n",
        "    for d in dirs:\n",
        "        print(os.path.join(root, d))\n",
        "    for f in files:\n",
        "        print(os.path.join(root, f))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, xarray as xr\n",
        "\n",
        "EXTRACT_DIR = \"/tmp/NORESM2_LM_full\"\n",
        "\n",
        "# Find all NetCDF files\n",
        "all_nc = [f.replace(\"\\\\\", \"/\") for f in glob.glob(f\"{EXTRACT_DIR}/**/*.nc\", recursive=True)]\n",
        "print(\"Total NetCDF files found:\", len(all_nc))\n",
        "\n",
        "# Select Input4MIPs emissions (CO2 preferred)\n",
        "input_files = [f for f in all_nc if any(v in f.lower() for v in [\"co2\", \"input4mips\", \"emission\"])]\n",
        "# Select CMIP6 climate outputs (tas = temperature)\n",
        "output_files = [f for f in all_nc if \"tas\" in f.lower() and \"ssp\" in f.lower()]\n",
        "\n",
        "print(f\"Input4MIPs candidates: {len(input_files)}\")\n",
        "print(f\"CMIP6 candidates: {len(output_files)}\")\n",
        "\n",
        "# Automatically pick the first valid files\n",
        "input_path = input_files[0] if input_files else None\n",
        "output_path = output_files[0] if output_files else None\n",
        "\n",
        "print(\"‚úÖ Selected Input4MIPs file:\", input_path)\n",
        "print(\"‚úÖ Selected CMIP6 file:\", output_path)\n"
      ],
      "metadata": {
        "id": "WteHEesGy6HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, xarray as xr\n",
        "\n",
        "EXTRACT_DIR = \"/tmp/NORESM2_LM_full\"\n",
        "\n",
        "# Find all NetCDF files (replace backslashes in paths)\n",
        "all_nc = [f.replace(\"\\\\\", \"/\") for f in glob.glob(f\"{EXTRACT_DIR}/**/*.nc\", recursive=True)]\n",
        "print(\"Total .nc files found:\", len(all_nc))\n",
        "\n",
        "# Pick one Input4MIPs CO2 file (preferably SSP126)\n",
        "input_files = [f for f in all_nc if \"ssp126\" in f.lower() and \"co2\" in f.lower()]\n",
        "# Pick one CMIP6 temperature (tas) file (same scenario SSP126)\n",
        "output_files = [f for f in all_nc if \"ssp126\" in f.lower() and \"tas\" in f.lower()]\n",
        "\n",
        "print(\"Input4MIPs CO2 candidates:\", len(input_files))\n",
        "print(\"CMIP6 tas candidates:\", len(output_files))\n",
        "\n",
        "input_path = input_files[0]\n",
        "output_path = output_files[0]\n",
        "\n",
        "print(\"‚úÖ Using Input file:\", input_path)\n",
        "print(\"‚úÖ Using Output file:\", output_path)\n"
      ],
      "metadata": {
        "id": "64sYS3ht0DSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, xarray as xr, os\n",
        "\n",
        "EXTRACT_DIR = \"/tmp/NORESM2_LM_full\"\n",
        "\n",
        "# Replace all backslashes in paths (so Colab can read them)\n",
        "all_nc = []\n",
        "for root, dirs, files in os.walk(EXTRACT_DIR):\n",
        "    for name in files:\n",
        "        if name.endswith(\".nc\"):\n",
        "            full_path = os.path.join(root, name).replace(\"\\\\\", \"/\")\n",
        "            all_nc.append(full_path)\n",
        "\n",
        "print(\"‚úÖ Total .nc files found:\", len(all_nc))\n",
        "\n",
        "# Now safely filter based on names\n",
        "input_candidates = [f for f in all_nc if \"ssp126\" in f.lower() and \"co2\" in f.lower()]\n",
        "output_candidates = [f for f in all_nc if \"ssp126\" in f.lower() and \"tas\" in f.lower()]\n",
        "\n",
        "print(\"Input candidates found:\", len(input_candidates))\n",
        "print(\"Output candidates found:\", len(output_candidates))\n",
        "\n",
        "# Let's preview the first few\n",
        "print(\"üü¢ Input example:\", input_candidates[:3])\n",
        "print(\"üü¢ Output example:\", output_candidates[:3])\n"
      ],
      "metadata": {
        "id": "MWdqyGy00QKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "count = 0\n",
        "for root, dirs, files in os.walk(\"/tmp/NORESM2_LM_full\"):\n",
        "    for f in files:\n",
        "        if f.endswith(\".nc\"):\n",
        "            print(f)\n",
        "            count += 1\n",
        "            if count >= 10:\n",
        "                break\n",
        "    if count >= 10:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "qDd2R6Cy0kzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base = \"/tmp/NORESM2_LM_full\"\n",
        "fixed = 0\n",
        "\n",
        "for root, dirs, files in os.walk(base):\n",
        "    for f in files:\n",
        "        if \"\\\\\" in f:\n",
        "            new_name = f.replace(\"\\\\\", \"_\")\n",
        "            os.rename(os.path.join(root, f), os.path.join(root, new_name))\n",
        "            fixed += 1\n",
        "\n",
        "print(f\"‚úÖ Renamed {fixed} files that contained backslashes in their names.\")\n"
      ],
      "metadata": {
        "id": "23Jcm80r0vlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "files = glob.glob(\"/tmp/NORESM2_LM_full/**/*.nc\", recursive=True)\n",
        "print(\"Total .nc files after rename:\", len(files))\n",
        "print(\"Example files:\")\n",
        "for f in files[:10]:\n",
        "    print(f)\n"
      ],
      "metadata": {
        "id": "-lQ8RDCA04XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = [f for f in files if \"ssp126\" in f and \"co2\" in f.lower()][0]\n",
        "output_path = [f for f in files if \"ssp126\" in f and \"tas\" in f.lower()][0]\n",
        "\n",
        "print(\"Input file:\", input_path)\n",
        "print(\"Output file:\", output_path)\n"
      ],
      "metadata": {
        "id": "4P56Lq0f07SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "\n",
        "input_path = [f for f in files if \"ssp126\" in f and \"co2\" in f.lower()][0]\n",
        "output_path = [f for f in files if \"ssp126\" in f and \"tas\" in f.lower()][0]\n",
        "\n",
        "print(\"üü¢ Input file:\", input_path)\n",
        "print(\"üü¢ Output file:\", output_path)\n",
        "\n",
        "# Open with decode_times=False to avoid calendar issue\n",
        "ds_in  = xr.open_dataset(input_path, decode_times=False)\n",
        "ds_out = xr.open_dataset(output_path, decode_times=False)\n",
        "\n",
        "print(\"‚úÖ Both files opened successfully (times not yet decoded).\")\n",
        "print(\"Input vars:\", list(ds_in.data_vars))\n",
        "print(\"Output vars:\", list(ds_out.data_vars))\n"
      ],
      "metadata": {
        "id": "_jm9Csxi1Eys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Fix Input4MIPs time axis\n",
        "if \"time\" in ds_in:\n",
        "    start_year = 2015  # approximate since all are monthly 2015‚Äì2100\n",
        "    ds_in[\"time\"] = pd.date_range(f\"{start_year}-01-01\", periods=ds_in.time.size, freq=\"MS\")\n",
        "\n",
        "# Fix CMIP6 output time axis\n",
        "if \"time\" in ds_out:\n",
        "    start_year = 2015\n",
        "    ds_out[\"time\"] = pd.date_range(f\"{start_year}-01-01\", periods=ds_out.time.size, freq=\"MS\")\n",
        "\n",
        "print(\"‚úÖ Time variables fixed and converted to standard datetime.\")\n"
      ],
      "metadata": {
        "id": "VBIGVsbu1VZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4 in 2 out**"
      ],
      "metadata": {
        "id": "yOfJkyjY2EEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, xarray as xr\n",
        "\n",
        "BASE = \"/tmp/NORESM2_LM_full\"\n",
        "\n",
        "# --- rename any files that still contain \"\\\" ---\n",
        "fixed = 0\n",
        "for root, _, files in os.walk(BASE):\n",
        "    for f in files:\n",
        "        if \"\\\\\" in f:\n",
        "            os.rename(os.path.join(root, f),\n",
        "                      os.path.join(root, f.replace(\"\\\\\", \"_\")))\n",
        "            fixed += 1\n",
        "print(f\"‚úÖ Renamed {fixed} files containing backslashes.\")\n",
        "\n",
        "# --- collect all .nc files ---\n",
        "all_nc = glob.glob(f\"{BASE}/**/*.nc\", recursive=True)\n",
        "\n",
        "# --- find 4 inputs + 2 outputs ---\n",
        "inputs = {v: [f for f in all_nc if \"ssp126\" in f.lower() and v in f.lower()]\n",
        "          for v in [\"co2\",\"ch4\",\"so2\",\"bc\"]}\n",
        "outputs = {v: [f for f in all_nc if \"ssp126\" in f.lower() and v in f.lower()]\n",
        "           for v in [\"tas\",\"pr\"]}\n",
        "\n",
        "for k,v in inputs.items():  print(f\"{k.upper()} files: {len(v)}\")\n",
        "for k,v in outputs.items(): print(f\"{k.upper()} files: {len(v)}\")\n",
        "\n",
        "# pick one file per variable\n",
        "paths_in  = {k:v[0] for k,v in inputs.items()  if v}\n",
        "paths_out = {k:v[0] for k,v in outputs.items() if v}\n"
      ],
      "metadata": {
        "id": "Rm1KlVH-1ijt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np\n",
        "\n",
        "def open_fix_time(path, start_year=2015):\n",
        "    ds = xr.open_dataset(path, decode_times=False)\n",
        "    if \"time\" in ds:\n",
        "        ds[\"time\"] = pd.date_range(f\"{start_year}-01-01\",\n",
        "                                   periods=ds.time.size, freq=\"MS\")\n",
        "    return ds\n",
        "\n",
        "ds_inputs  = {k: open_fix_time(p) for k,p in paths_in.items()}\n",
        "ds_outputs = {k: open_fix_time(p) for k,p in paths_out.items()}\n",
        "print(\"‚úÖ All 6 datasets opened and time fixed.\")\n"
      ],
      "metadata": {
        "id": "8g3eVgbV2HW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Emission units\n",
        "for k,ds in ds_inputs.items():\n",
        "    for v in ds.data_vars:\n",
        "        ds[v].attrs[\"units\"] = \"kg m-2 s-1\"\n",
        "\n",
        "# Temperature Kelvin‚Üí¬∞C\n",
        "if \"tas\" in ds_outputs:\n",
        "    if ds_outputs[\"tas\"][\"tas\"].attrs.get(\"units\",\"\").lower() in [\"k\",\"kelvin\"]:\n",
        "        ds_outputs[\"tas\"][\"tas\"] = ds_outputs[\"tas\"][\"tas\"] - 273.15\n",
        "        ds_outputs[\"tas\"][\"tas\"].attrs[\"units\"] = \"degC\"\n",
        "\n",
        "print(\"‚úÖ Units normalized.\")\n"
      ],
      "metadata": {
        "id": "XzkWOX642MRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose reference grid (Temperature)\n",
        "ref = ds_outputs[\"tas\"]\n",
        "\n",
        "for k,ds in ds_inputs.items():\n",
        "    ds_inputs[k] = ds.sel(time=slice(\"2015-01-01\",\"2025-12-31\"))\n",
        "    if (ds.lat.size != ref.lat.size) or (ds.lon.size != ref.lon.size):\n",
        "        ds_inputs[k] = ds_inputs[k].interp(lat=ref.lat, lon=ref.lon)\n",
        "\n",
        "for k,ds in ds_outputs.items():\n",
        "    ds_outputs[k] = ds.sel(time=slice(\"2015-01-01\",\"2025-12-31\"))\n",
        "\n",
        "print(\"‚úÖ Temporal slice & grid alignment done.\")\n"
      ],
      "metadata": {
        "id": "evlzwPdD2PRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_vars = {}\n",
        "\n",
        "# 4 inputs\n",
        "for name,ds in ds_inputs.items():\n",
        "    v = list(ds.data_vars)[0]\n",
        "    data_vars[name.upper()] = ds[v]\n",
        "\n",
        "# 2 outputs\n",
        "for name,ds in ds_outputs.items():\n",
        "    v = list(ds.data_vars)[0]\n",
        "    rename = \"Temperature\" if name==\"tas\" else \"Precipitation\"\n",
        "    data_vars[rename] = ds[v]\n",
        "\n",
        "combined = xr.Dataset(data_vars).dropna(dim=\"time\", how=\"all\")\n",
        "\n",
        "combined.attrs = {\n",
        "    \"source\": \"NorESM2-LM\",\n",
        "    \"scenario\": \"SSP126\",\n",
        "    \"inputs\": \"CO2,CH4,SO2,BC\",\n",
        "    \"outputs\": \"Temperature,Precipitation\",\n",
        "    \"years\": \"2015‚Äì2025\",\n",
        "    \"temporal_res\": \"monthly\",\n",
        "    \"spatial_res\": \"‚âà250 km\",\n",
        "    \"created_by\": \"Richee\"\n",
        "}\n",
        "print(\"‚úÖ Unified 4 input + 2 output dataset built.\")\n",
        "combined\n"
      ],
      "metadata": {
        "id": "fJxys2YG2Rkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = \"/content/drive/MyDrive/ClimateProject/NORESM2_LM_2015_2025_4in2out.nc\"\n",
        "combined.to_netcdf(SAVE_PATH)\n",
        "print(\"‚úÖ Saved:\", SAVE_PATH)\n"
      ],
      "metadata": {
        "id": "8fHRtnde2UUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "combined[\"Temperature\"].isel(time=0).plot()\n",
        "plt.title(\"Global Temperature (¬∞C) ‚Äî Jan 2015 (SSP126)\")\n",
        "plt.show()\n",
        "\n",
        "combined[\"CO2\"].isel(time=0).plot()\n",
        "plt.title(\"CO‚ÇÇ Emissions (kg m‚Åª¬≤ s‚Åª¬π) ‚Äî Jan 2015 (SSP126)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X3ULP-Fn2ZP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check time coverage for each dataset\n",
        "def show_time_info(label, ds):\n",
        "    if \"time\" in ds:\n",
        "        t0 = str(ds.time.values[0])[:10]\n",
        "        t1 = str(ds.time.values[-1])[:10]\n",
        "        print(f\"{label} ‚Üí {t0}  to  {t1}  ({ds.time.size} time steps)\")\n",
        "    else:\n",
        "        print(f\"{label} ‚Üí ‚ö†Ô∏è No 'time' dimension found\")\n",
        "\n",
        "for k, ds in ds_inputs.items():\n",
        "    show_time_info(f\"Input {k.upper()}\", ds)\n",
        "\n",
        "for k, ds in ds_outputs.items():\n",
        "    show_time_info(f\"Output {k.upper()}\", ds)\n"
      ],
      "metadata": {
        "id": "p5Im4iEF2dNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset to desired window\n",
        "start_year, end_year = 2015, 2025\n",
        "\n",
        "for k in ds_inputs:\n",
        "    if \"time\" in ds_inputs[k]:\n",
        "        ds_inputs[k] = ds_inputs[k].sel(time=slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\"))\n",
        "\n",
        "for k in ds_outputs:\n",
        "    if \"time\" in ds_outputs[k]:\n",
        "        ds_outputs[k] = ds_outputs[k].sel(time=slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\"))\n",
        "\n",
        "print(f\"‚úÖ Datasets trimmed to {start_year}‚Äì{end_year}.\")\n"
      ],
      "metadata": {
        "id": "mZwPD3kW3Gvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, ds in ds_inputs.items():\n",
        "    show_time_info(f\"Trimmed Input {k.upper()}\", ds)\n",
        "\n",
        "for k, ds in ds_outputs.items():\n",
        "    show_time_info(f\"Trimmed Output {k.upper()}\", ds)\n"
      ],
      "metadata": {
        "id": "AUwE09-k3MQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "def get_yearly_files(variable):\n",
        "    paths = sorted([f for f in all_nc\n",
        "                    if \"ssp126\" in f.lower() and variable.lower() in f.lower()\n",
        "                    and any(str(y) in f for y in range(2015, 2026))])\n",
        "    print(f\"{variable.upper()}: {len(paths)} yearly files found.\")\n",
        "    return paths\n",
        "\n",
        "co2_files = get_yearly_files(\"co2\")\n",
        "ch4_files = get_yearly_files(\"ch4\")\n",
        "so2_files = get_yearly_files(\"so2\")\n",
        "bc_files  = get_yearly_files(\"bc\")\n",
        "tas_files = get_yearly_files(\"tas\")\n",
        "pr_files  = get_yearly_files(\"pr\")\n"
      ],
      "metadata": {
        "id": "YhesK2LU3Of4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def open_concat(paths):\n",
        "    ds = xr.open_mfdataset(paths, combine=\"by_coords\", decode_times=False)\n",
        "    ds[\"time\"] = pd.date_range(\"2015-01-01\", periods=ds.time.size, freq=\"MS\")\n",
        "    return ds\n",
        "\n",
        "ds_in = {\n",
        "    \"co2\": open_concat(co2_files),\n",
        "    \"ch4\": open_concat(ch4_files),\n",
        "    \"so2\": open_concat(so2_files),\n",
        "    \"bc\" : open_concat(bc_files)\n",
        "}\n",
        "\n",
        "ds_out = {\n",
        "    \"tas\": open_concat(tas_files),\n",
        "    \"pr\" : open_concat(pr_files)\n",
        "}\n",
        "\n",
        "print(\"‚úÖ All yearly files concatenated (2015‚Äì2025).\")\n"
      ],
      "metadata": {
        "id": "lpD4fP763luz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, ds in ds_in.items():\n",
        "    print(f\"Input {k.upper()} ‚Üí {str(ds.time.values[0])[:10]} to {str(ds.time.values[-1])[:10]} ({ds.time.size} steps)\")\n",
        "for k, ds in ds_out.items():\n",
        "    print(f\"Output {k.upper()} ‚Üí {str(ds.time.values[0])[:10]} to {str(ds.time.values[-1])[:10]} ({ds.time.size} steps)\")\n"
      ],
      "metadata": {
        "id": "R30xhMDy3qEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kelvin ‚Üí Celsius for temperature\n",
        "if \"tas\" in ds_out:\n",
        "    if ds_out[\"tas\"][\"tas\"].attrs.get(\"units\", \"\").lower() in [\"k\", \"kelvin\"]:\n",
        "        ds_out[\"tas\"][\"tas\"] = ds_out[\"tas\"][\"tas\"] - 273.15\n",
        "        ds_out[\"tas\"][\"tas\"].attrs[\"units\"] = \"degC\"\n",
        "\n",
        "# Standardize input emission units\n",
        "for k, ds in ds_in.items():\n",
        "    for v in ds.data_vars:\n",
        "        ds[v].attrs[\"units\"] = \"kg m-2 s-1\"\n",
        "\n",
        "# Choose reference grid (Temperature)\n",
        "ref = ds_out[\"tas\"]\n",
        "\n",
        "# Align all inputs spatially and temporally\n",
        "for k in ds_in:\n",
        "    ds_in[k] = ds_in[k].sel(time=slice(\"2015-01-01\", \"2025-12-31\"))\n",
        "    if (ds_in[k].lat.size != ref.lat.size) or (ds_in[k].lon.size != ref.lon.size):\n",
        "        ds_in[k] = ds_in[k].interp(lat=ref.lat, lon=ref.lon)\n",
        "\n",
        "# Align outputs as well\n",
        "for k in ds_out:\n",
        "    ds_out[k] = ds_out[k].sel(time=slice(\"2015-01-01\", \"2025-12-31\"))\n",
        "\n",
        "print(\"‚úÖ Units normalized & grids aligned across all 6 variables.\")\n"
      ],
      "metadata": {
        "id": "2yV-VXOR3win"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "\n",
        "data_vars = {}\n",
        "\n",
        "# 4 Inputs\n",
        "for k, ds in ds_in.items():\n",
        "    v = list(ds.data_vars)[0]\n",
        "    data_vars[k.upper()] = ds[v]\n",
        "\n",
        "# 2 Outputs\n",
        "data_vars[\"Temperature\"]    = ds_out[\"tas\"][\"tas\"]\n",
        "data_vars[\"Precipitation\"]  = ds_out[\"pr\"][list(ds_out[\"pr\"].data_vars)[0]]\n",
        "\n",
        "# Combine all into one dataset\n",
        "combined = xr.Dataset(data_vars).dropna(dim=\"time\", how=\"all\")\n",
        "\n",
        "# Metadata\n",
        "combined.attrs = {\n",
        "    \"source\": \"NorESM2-LM\",\n",
        "    \"scenario\": \"SSP126\",\n",
        "    \"inputs\": \"CO2, CH4, SO2, BC\",\n",
        "    \"outputs\": \"Temperature, Precipitation\",\n",
        "    \"years\": \"2015‚Äì2025\",\n",
        "    \"year_start\": 2015,\n",
        "    \"year_end\": 2025,\n",
        "    \"temporal_res\": \"monthly\",\n",
        "    \"spatial_res\": \"‚âà250 km\",\n",
        "    \"created_by\": \"Richee\",\n",
        "    \"pipeline_stages\": \"Downloader ‚Üí Checker ‚Üí RawProcessor ‚Üí ResolutionProcessor ‚Üí StructureProcessor\"\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Unified 4-input, 2-output dataset created successfully.\")\n",
        "combined\n"
      ],
      "metadata": {
        "id": "x1kLaI7o4aHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = \"/content/drive/MyDrive/ClimateProject/NORESM2_LM_2015_2025_4in2out.nc\"\n",
        "combined.to_netcdf(SAVE_PATH)\n",
        "print(\"‚úÖ Saved final ML-ready dataset at:\", SAVE_PATH)\n"
      ],
      "metadata": {
        "id": "kEUex4IG4cLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Variables:\", list(combined.data_vars))\n",
        "print(\"Dimensions:\", combined.dims)\n",
        "print(\"Time span:\", str(combined.time.values[0])[:10], \"to\", str(combined.time.values[-1])[:10])\n"
      ],
      "metadata": {
        "id": "fu6lZkHp4hWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot 1 ‚Äî Surface temperature\n",
        "combined[\"Temperature\"].isel(time=0).plot()\n",
        "plt.title(\"üå°Ô∏è Global Temperature (¬∞C) ‚Äî Jan 2015\")\n",
        "plt.show()\n",
        "\n",
        "# Plot 2 ‚Äî CO‚ÇÇ emissions\n",
        "combined[\"CO2\"].isel(time=0).plot()\n",
        "plt.title(\"üí® CO‚ÇÇ Emissions (kg m‚Åª¬≤ s‚Åª¬π) ‚Äî Jan 2015\")\n",
        "plt.show()\n",
        "\n",
        "# Plot 3 ‚Äî Precipitation\n",
        "combined[\"Precipitation\"].isel(time=0).plot()\n",
        "plt.title(\"üåßÔ∏è Precipitation (mm/day) ‚Äî Jan 2015\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "unwDX_u84mVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 6 Preparing for ML ready **"
      ],
      "metadata": {
        "id": "UsfPUJdT5YGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "\n",
        "path = \"/content/drive/MyDrive/ClimateProject/NORESM2_LM_2015_2025_4in2out.nc\"\n",
        "ds = xr.open_dataset(path)\n",
        "print(\"‚úÖ Loaded ClimateSet mini-dataset.\")\n",
        "print(\"Variables:\", list(ds.data_vars))\n",
        "print(\"Dimensions:\", ds.dims)\n"
      ],
      "metadata": {
        "id": "cLPoXG9y4tfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_vars  = [\"CO2\", \"CH4\", \"SO2\", \"BC\"]\n",
        "output_vars = [\"Temperature\", \"Precipitation\"]\n",
        "\n",
        "# Stack into NumPy arrays\n",
        "X = np.stack([ds[v].values for v in input_vars], axis=1)  # shape = [time, 4, y, x]\n",
        "Y = np.stack([ds[v].values for v in output_vars], axis=1) # shape = [time, 2, y, x]\n",
        "\n",
        "print(\"X shape (inputs):\", X.shape)\n",
        "print(\"Y shape (outputs):\", Y.shape)\n"
      ],
      "metadata": {
        "id": "MMnOTdfI5to5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Min‚Äìmax normalization across each variable\n",
        "X_norm = np.empty_like(X)\n",
        "Y_norm = np.empty_like(Y)\n",
        "\n",
        "for i in range(X.shape[1]):\n",
        "    vmin, vmax = np.nanmin(X[:, i, :, :]), np.nanmax(X[:, i, :, :])\n",
        "    X_norm[:, i, :, :] = (X[:, i, :, :] - vmin) / (vmax - vmin + 1e-8)\n",
        "\n",
        "for i in range(Y.shape[1]):\n",
        "    vmin, vmax = np.nanmin(Y[:, i, :, :]), np.nanmax(Y[:, i, :, :])\n",
        "    Y_norm[:, i, :, :] = (Y[:, i, :, :] - vmin) / (vmax - vmin + 1e-8)\n",
        "\n",
        "print(\"‚úÖ Normalized all variables for ML training.\")\n"
      ],
      "metadata": {
        "id": "wbvKiPKx5xG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/ClimateProject/X_2015_2025_4inputs.npy\", X_norm)\n",
        "np.save(\"/content/drive/MyDrive/ClimateProject/Y_2015_2025_2outputs.npy\", Y_norm)\n",
        "print(\"‚úÖ Saved ML-ready arrays to Drive.\")\n"
      ],
      "metadata": {
        "id": "dpiwC_xC5z6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "t = 0  # first month\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
        "axes[0].imshow(X_norm[t, 0, :, :], cmap=\"inferno\")\n",
        "axes[0].set_title(\"CO‚ÇÇ (normalized) ‚Äî Jan 2015\")\n",
        "axes[1].imshow(Y_norm[t, 0, :, :], cmap=\"coolwarm\")\n",
        "axes[1].set_title(\"Temperature (normalized) ‚Äî Jan 2015\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdyeAPrp52sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 7 ML Emulator Training **"
      ],
      "metadata": {
        "id": "xjM3u3UP6Fkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision tqdm -q\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "tf2mJagN55z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load(\"/content/drive/MyDrive/ClimateProject/X_2015_2025_4inputs.npy\")\n",
        "Y = np.load(\"/content/drive/MyDrive/ClimateProject/Y_2015_2025_2outputs.npy\")\n",
        "\n",
        "print(\"‚úÖ Loaded data:\", X.shape, Y.shape)\n"
      ],
      "metadata": {
        "id": "7bG2PbUe6N9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClimateDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        # ensure shape is [time, ch, height, width] = [132, ch, 96, 144]\n",
        "        if X.shape[-2] != 96:\n",
        "            X = np.transpose(X, (0, 1, 3, 2))  # swap last two dims\n",
        "        if Y.shape[-2] != 96:\n",
        "            Y = np.transpose(Y, (0, 1, 3, 2))\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n"
      ],
      "metadata": {
        "id": "PfWEYUGF6VpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ClimateDataset(X, Y)\n",
        "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "print(\"‚úÖ Dataset fixed: X shape\", dataset.X.shape, \"| Y shape\", dataset.Y.shape)\n"
      ],
      "metadata": {
        "id": "2DXsIN_v6zZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleUNet(nn.Module):\n",
        "    def __init__(self, in_ch=4, out_ch=2):\n",
        "        super(SimpleUNet, self).__init__()\n",
        "        self.enc1 = nn.Sequential(nn.Conv2d(in_ch, 32, 3, padding=1), nn.ReLU(), nn.Conv2d(32, 32, 3, padding=1), nn.ReLU())\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = nn.Sequential(nn.Conv2d(32, 64, 3, padding=1), nn.ReLU())\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.middle = nn.Sequential(nn.Conv2d(64, 128, 3, padding=1), nn.ReLU())\n",
        "        self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        self.dec1 = nn.Sequential(nn.Conv2d(128, 64, 3, padding=1), nn.ReLU())\n",
        "        self.up2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        self.dec2 = nn.Sequential(nn.Conv2d(64, 32, 3, padding=1), nn.ReLU(), nn.Conv2d(32, out_ch, 1))\n",
        "    def forward(self, x):\n",
        "        x1 = self.enc1(x)\n",
        "        x2 = self.pool1(x1)\n",
        "        x3 = self.enc2(x2)\n",
        "        x4 = self.pool2(x3)\n",
        "        x5 = self.middle(x4)\n",
        "        x6 = self.up1(x5)\n",
        "        x7 = self.dec1(x6)\n",
        "        x8 = self.up2(x7)\n",
        "        out = self.dec2(x8)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "zK_WlvCg6X2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")  # CPU mode\n",
        "model = SimpleUNet(in_ch=4, out_ch=2).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"‚úÖ Model initialized (CPU mode).\")\n"
      ],
      "metadata": {
        "id": "IDvr7eSz6bHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace NaN or Inf with finite values\n",
        "X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "Y = np.nan_to_num(Y, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "print(\"‚úÖ Replaced NaN/Inf with zeros.\")\n"
      ],
      "metadata": {
        "id": "jvP22yAs6hUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X range:\", np.nanmin(X), \"‚Üí\", np.nanmax(X))\n",
        "print(\"Y range:\", np.nanmin(Y), \"‚Üí\", np.nanmax(Y))\n"
      ],
      "metadata": {
        "id": "Qt6ARa-m7PwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)  # smaller LR\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for Xb, Yb in tqdm(train_loader, desc=f\"Epoch {epoch+1}/10\"):\n",
        "        Xb, Yb = Xb.to(device), Yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(Xb)\n",
        "        preds = torch.nan_to_num(preds)   # avoid inf/NaN in prediction\n",
        "        loss = criterion(preds, Yb)\n",
        "        if torch.isnan(loss):\n",
        "            print(\"‚ö†Ô∏è NaN loss detected ‚Äî skipping batch.\")\n",
        "            continue\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # prevent exploding grads\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss/len(train_loader):.6f}\")\n"
      ],
      "metadata": {
        "id": "p0p7rujC7RxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConvLSTM Climate Emulator (4 Inputs ‚Üí 2 Outputs, 2015‚Äì2025)**"
      ],
      "metadata": {
        "id": "s8_30SjO90F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision tqdm -q\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "yG-GnaOg9zRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load(\"/content/drive/MyDrive/ClimateProject/X_2015_2025_4inputs.npy\")\n",
        "Y = np.load(\"/content/drive/MyDrive/ClimateProject/Y_2015_2025_2outputs.npy\")\n",
        "\n",
        "# fix axis order if needed\n",
        "if X.shape[-2] != 96: X = np.transpose(X, (0,1,3,2))\n",
        "if Y.shape[-2] != 96: Y = np.transpose(Y, (0,1,3,2))\n",
        "\n",
        "print(\"Data shapes:\", X.shape, Y.shape)   # (132, 4, 96, 144), (132, 2, 96, 144)\n"
      ],
      "metadata": {
        "id": "L38AEF437XA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClimateSeqDataset(Dataset):\n",
        "    def __init__(self, X, Y, seq_len=6):\n",
        "        self.seq_len = seq_len\n",
        "        self.X_seq, self.Y_seq = [], []\n",
        "        for i in range(len(X)-seq_len):\n",
        "            self.X_seq.append(X[i:i+seq_len])\n",
        "            self.Y_seq.append(Y[i+seq_len])\n",
        "        self.X_seq, self.Y_seq = np.array(self.X_seq), np.array(self.Y_seq)\n",
        "    def __len__(self): return len(self.X_seq)\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.X_seq[idx], dtype=torch.float32), \\\n",
        "               torch.tensor(self.Y_seq[idx], dtype=torch.float32)\n",
        "\n",
        "dataset = ClimateSeqDataset(X, Y, seq_len=6)\n",
        "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "print(\"‚úÖ Sequence dataset built:\", len(dataset), \"samples, each 6 months ‚Üí next month\")\n"
      ],
      "metadata": {
        "id": "kz0sTCRk99Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvLSTMCell(nn.Module):\n",
        "    def __init__(self, in_ch, hidden_ch, kernel_size=3):\n",
        "        super().__init__()\n",
        "        pad = kernel_size // 2\n",
        "        self.hidden_ch = hidden_ch\n",
        "        self.conv = nn.Conv2d(in_ch + hidden_ch, 4 * hidden_ch, kernel_size, padding=pad)\n",
        "\n",
        "    def forward(self, x, h, c):\n",
        "        # Replace any NaNs/Infs with zeros\n",
        "        x = torch.nan_to_num(x)\n",
        "        h = torch.nan_to_num(h)\n",
        "        c = torch.nan_to_num(c)\n",
        "\n",
        "        combined = torch.cat([x, h], dim=1)\n",
        "        conv_out = self.conv(combined)\n",
        "        i, f, o, g = torch.split(conv_out, self.hidden_ch, dim=1)\n",
        "        i, f, o = torch.sigmoid(i), torch.sigmoid(f), torch.sigmoid(o)\n",
        "        g = torch.tanh(g)\n",
        "        c_next = f * c + i * g\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "\n",
        "        # Clamp to prevent explosion\n",
        "        h_next = torch.clamp(h_next, -5, 5)\n",
        "        c_next = torch.clamp(c_next, -5, 5)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "\n",
        "class ConvLSTMEmulator(nn.Module):\n",
        "    def __init__(self, in_ch=4, hidden_ch=16, out_ch=2):\n",
        "        super().__init__()\n",
        "        self.cell = ConvLSTMCell(in_ch, hidden_ch)\n",
        "        self.conv_out = nn.Conv2d(hidden_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, seq):\n",
        "        b, t, c, h, w = seq.size()\n",
        "        h_t = torch.zeros(b, 16, h, w, device=seq.device)\n",
        "        c_t = torch.zeros_like(h_t)\n",
        "        for i in range(t):\n",
        "            h_t, c_t = self.cell(seq[:, i], h_t, c_t)\n",
        "        out = self.conv_out(h_t)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "aeliqOvx-AAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "Y = np.nan_to_num(Y, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "print(\"‚úÖ Data cleaned:\", np.isnan(X).sum(), \"NaNs in X,\", np.isnan(Y).sum(), \"in Y\")\n"
      ],
      "metadata": {
        "id": "wTlYT99R-tQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")\n",
        "model = ConvLSTMEmulator().to(device)\n",
        "\n",
        "# Use a more stable loss\n",
        "criterion = nn.SmoothL1Loss()   # Huber loss instead of MSE\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-4)  # smaller, safer LR\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for Xb, Yb in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "        Xb, Yb = Xb.to(device), Yb.to(device)\n",
        "\n",
        "        # Replace NaN / Inf before forward pass\n",
        "        Xb = torch.nan_to_num(Xb, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        Yb = torch.nan_to_num(Yb, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(Xb)\n",
        "\n",
        "        # Replace any NaN predictions\n",
        "        preds = torch.nan_to_num(preds, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "        loss = criterion(preds, Yb)\n",
        "\n",
        "        # Skip if loss is NaN\n",
        "        if torch.isnan(loss):\n",
        "            print(\"‚ö†Ô∏è NaN loss detected ‚Äî skipping batch.\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    rmse = (avg_loss ** 0.5)\n",
        "    print(f\"Epoch {epoch+1}: Loss = {avg_loss:.6f} | RMSE = {rmse:.6f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"‚úÖ Training finished successfully.\")\n"
      ],
      "metadata": {
        "id": "w5soInFg-F0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RMSE VISUALIZATION**"
      ],
      "metadata": {
        "id": "liqc7g10ChnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "preds_all = []\n",
        "trues_all = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for Xb, Yb in train_loader:\n",
        "        Xb, Yb = Xb.to(device), Yb.to(device)\n",
        "        pred = model(Xb)\n",
        "        preds_all.append(pred.cpu().numpy())\n",
        "        trues_all.append(Yb.cpu().numpy())\n",
        "\n",
        "preds_all = np.concatenate(preds_all, axis=0)\n",
        "trues_all = np.concatenate(trues_all, axis=0)\n",
        "\n",
        "print(\"‚úÖ Predictions collected:\", preds_all.shape, trues_all.shape)\n"
      ],
      "metadata": {
        "id": "ABw-uykXAeJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_map = np.sqrt(np.mean((preds_all - trues_all) ** 2, axis=0))\n",
        "print(\"RMSE map shape:\", rmse_map.shape)\n"
      ],
      "metadata": {
        "id": "QNGBMAPcCmc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "titles = [\"Temperature RMSE (¬∞C)\", \"Precipitation RMSE (mm/day)\"]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "for i, ax in enumerate(axes):\n",
        "    im = ax.imshow(rmse_map[i], cmap=\"magma\", origin=\"lower\")\n",
        "    ax.set_title(titles[i])\n",
        "    plt.colorbar(im, ax=ax, shrink=0.7)\n",
        "plt.suptitle(\"üåé Spatial RMSE Maps ‚Äî ConvLSTM Emulator (2015‚Äì2025)\", fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "d74FlXVTCs9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_norm = rmse_map / np.max(rmse_map, axis=(1,2), keepdims=True)\n"
      ],
      "metadata": {
        "id": "o0x5EpCTCvTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üå°Ô∏è  Mean RMSE (Temperature):\", np.mean(rmse_map[0]))\n",
        "print(\"üåßÔ∏è  Mean RMSE (Precipitation):\", np.mean(rmse_map[1]))\n"
      ],
      "metadata": {
        "id": "dZE1xjpwC1ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Real Earth Projection**"
      ],
      "metadata": {
        "id": "QxAPeOENDEVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_map.shape = (2, 96, 144)\n"
      ],
      "metadata": {
        "id": "4HglTWNcC3rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy -q\n"
      ],
      "metadata": {
        "id": "JWRlq1ivDNYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Regular 2.5¬∞ grid (since 144√ó96 = 360/2.5 √ó 180/2.5)\n",
        "lons = np.linspace(-180, 180, 144)\n",
        "lats = np.linspace(-90, 90, 96)\n",
        "lon2d, lat2d = np.meshgrid(lons, lats)\n",
        "\n",
        "print(\"Latitude range:\", lats[0], \"‚Üí\", lats[-1])\n",
        "print(\"Longitude range:\", lons[0], \"‚Üí\", lons[-1])\n"
      ],
      "metadata": {
        "id": "jYXU8o2hDPYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "titles = [\"Temperature RMSE (¬∞C)\", \"Precipitation RMSE (mm/day)\"]\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "for i in range(2):\n",
        "    ax = plt.subplot(1, 2, i + 1, projection=ccrs.PlateCarree())\n",
        "    ax.set_global()\n",
        "    im = ax.pcolormesh(lon2d, lat2d, rmse_map[i],\n",
        "                       cmap=\"magma\", shading=\"auto\", transform=ccrs.PlateCarree())\n",
        "    ax.coastlines(linewidth=0.8)\n",
        "    ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
        "    ax.set_title(titles[i], fontsize=12)\n",
        "    plt.colorbar(im, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)\n",
        "plt.suptitle(\"üåé Spatial RMSE Maps ‚Äî ConvLSTM Emulator (NorESM2-LM, 2015‚Äì2025)\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AyxAjv7kDVkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_norm = rmse_map / np.nanmax(rmse_map, axis=(1,2), keepdims=True)\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "for i in range(2):\n",
        "    ax = plt.subplot(1, 2, i + 1, projection=ccrs.PlateCarree())\n",
        "    ax.set_global()\n",
        "    im = ax.pcolormesh(lon2d, lat2d, rmse_norm[i], cmap=\"plasma\", transform=ccrs.PlateCarree())\n",
        "    ax.coastlines(linewidth=0.8)\n",
        "    ax.set_title(f\"{titles[i]} (Normalized 0‚Äì1)\")\n",
        "    plt.colorbar(im, ax=ax, orientation='horizontal', pad=0.05, shrink=0.8)\n",
        "plt.suptitle(\"üåé Normalized RMSE Comparison\", fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hH8yw10_DZBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"üå°Ô∏è Global mean Temperature RMSE: {np.mean(rmse_map[0]):.3f} ¬∞C\")\n",
        "print(f\"üåßÔ∏è Global mean Precipitation RMSE: {np.mean(rmse_map[1]):.3f} mm/day\")\n"
      ],
      "metadata": {
        "id": "Byn02UacDhWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the maps for report**"
      ],
      "metadata": {
        "id": "SYO8kEyQDwVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "\n",
        "# make sure lats/lons and rmse_map are defined\n",
        "ds_rmse = xr.Dataset(\n",
        "    data_vars={\n",
        "        \"Temperature_RMSE\": ((\"lat\", \"lon\"), rmse_map[0]),\n",
        "        \"Precipitation_RMSE\": ((\"lat\", \"lon\"), rmse_map[1]),\n",
        "    },\n",
        "    coords={\n",
        "        \"lat\": lats,\n",
        "        \"lon\": lons\n",
        "    },\n",
        "    attrs={\n",
        "        \"source_model\": \"NorESM2-LM ConvLSTM Emulator\",\n",
        "        \"years\": \"2015‚Äì2025\",\n",
        "        \"description\": \"Spatial RMSE of ConvLSTM emulator (TAS & PR)\",\n",
        "        \"units\": \"¬∞C (TAS), mm/day (PR)\"\n",
        "    }\n",
        ")\n",
        "\n",
        "save_path_nc = \"/content/drive/MyDrive/ClimateProject/RMSE_maps_2015_2025.nc\"\n",
        "ds_rmse.to_netcdf(save_path_nc)\n",
        "print(f\"‚úÖ RMSE maps saved as NetCDF: {save_path_nc}\")\n"
      ],
      "metadata": {
        "id": "BZaAyj8HDl4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "titles = [\"Temperature RMSE (¬∞C)\", \"Precipitation RMSE (mm/day)\"]\n",
        "file_names = [\"Temperature_RMSE.png\", \"Precipitation_RMSE.png\"]\n",
        "\n",
        "for i in range(2):\n",
        "    fig = plt.figure(figsize=(8, 4))\n",
        "    ax = plt.subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
        "    ax.set_global()\n",
        "    im = ax.pcolormesh(lon2d, lat2d, rmse_map[i],\n",
        "                       cmap=\"magma\", shading=\"auto\", transform=ccrs.PlateCarree())\n",
        "    ax.coastlines(linewidth=0.8)\n",
        "    ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
        "    ax.set_title(f\"{titles[i]} (2015‚Äì2025)\", fontsize=12)\n",
        "    plt.colorbar(im, ax=ax, orientation=\"horizontal\", pad=0.05, shrink=0.8)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_path_png = f\"/content/drive/MyDrive/ClimateProject/{file_names[i]}\"\n",
        "    plt.savefig(save_path_png, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "    print(f\"‚úÖ Saved: {save_path_png}\")\n"
      ],
      "metadata": {
        "id": "9RqXOCdtD3tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload & check from file\n",
        "check = xr.open_dataset(save_path_nc)\n",
        "print(check)\n"
      ],
      "metadata": {
        "id": "-0iD9TfND4Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot showing diff between actual and predicted**"
      ],
      "metadata": {
        "id": "Wcl1Wi8eG7j1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*1)Simple line plot*"
      ],
      "metadata": {
        "id": "7uE3V-sCHQXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# preds_all, trues_all shapes: [samples, 2, lat, lon]\n",
        "# Take spatial mean for each timestep\n",
        "true_mean = np.mean(trues_all, axis=(2,3))\n",
        "pred_mean = np.mean(preds_all, axis=(2,3))\n",
        "\n",
        "months = np.arange(len(true_mean))  # each step = 1 month\n",
        "variables = [\"Temperature (¬∞C)\", \"Precipitation (mm/day)\"]\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "for i in range(2):\n",
        "    plt.subplot(1,2,i+1)\n",
        "    plt.plot(months, true_mean[:, i], label=\"Actual\", color='black')\n",
        "    plt.plot(months, pred_mean[:, i], label=\"Predicted\", color='orange', linestyle='--')\n",
        "    plt.title(variables[i])\n",
        "    plt.xlabel(\"Months since Jan 2015\")\n",
        "    plt.ylabel(variables[i])\n",
        "    plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iOnF1ASeD8uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*2)Scatter plot*"
      ],
      "metadata": {
        "id": "LNiCiV1LHVx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "for i, var in enumerate([\"Temperature\", \"Precipitation\"]):\n",
        "    plt.subplot(1,2,i+1)\n",
        "    plt.scatter(trues_all[:, i, :, :].flatten(),\n",
        "                preds_all[:, i, :, :].flatten(),\n",
        "                s=1, alpha=0.3)\n",
        "    plt.plot([-1,1],[ -1,1 ], 'r--')  # reference diagonal\n",
        "    plt.title(f\"{var}: Predicted vs Actual\")\n",
        "    plt.xlabel(\"Actual\")\n",
        "    plt.ylabel(\"Predicted\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9I0PUOi6HFwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)Spatial map Prediction Error"
      ],
      "metadata": {
        "id": "wlW0ZzFLH5AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "mean_error = np.mean(preds_all - trues_all, axis=0)  # [2, lat, lon]\n",
        "\n",
        "titles = [\"Temperature Mean Error (¬∞C)\", \"Precipitation Mean Error (mm/day)\"]\n",
        "fig = plt.figure(figsize=(14,5))\n",
        "for i in range(2):\n",
        "    ax = plt.subplot(1,2,i+1, projection=ccrs.PlateCarree())\n",
        "    im = ax.pcolormesh(lon2d, lat2d, mean_error[i], cmap=\"coolwarm\", transform=ccrs.PlateCarree())\n",
        "    ax.coastlines(); ax.add_feature(cfeature.BORDERS, linewidth=0.5)\n",
        "    ax.set_title(titles[i])\n",
        "    plt.colorbar(im, ax=ax, orientation='horizontal', pad=0.05)\n",
        "plt.suptitle(\"üåç Mean Prediction Error (Predicted ‚àí Actual)\", fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bMNdfPgrHblS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*4)Histogram of error Distributiom*"
      ],
      "metadata": {
        "id": "bvgSabA8IRlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "for i, var in enumerate([\"Temperature\", \"Precipitation\"]):\n",
        "    plt.subplot(1,2,i+1)\n",
        "    err = (preds_all[:, i, :, :] - trues_all[:, i, :, :]).flatten()\n",
        "    plt.hist(err, bins=50, color='skyblue', edgecolor='black')\n",
        "    plt.title(f\"{var} Error Distribution\")\n",
        "    plt.xlabel(\"Predicted ‚àí Actual\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qLvphhqjIAUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*5)Animated*"
      ],
      "metadata": {
        "id": "Kwv56B4MItR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_all.shape, trues_all.shape  # => (time, 2, lat, lon)\n"
      ],
      "metadata": {
        "id": "gDKHjzCzIdXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "lons = np.linspace(-180, 180, 144)\n",
        "lats = np.linspace(-90, 90, 96)\n",
        "lon2d, lat2d = np.meshgrid(lons, lats)\n"
      ],
      "metadata": {
        "id": "dny5DzGUIyuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "\n",
        "# Choose variable index (0 = Temperature, 1 = Precipitation)\n",
        "var_index = 0\n",
        "var_name = [\"Temperature (¬∞C)\", \"Precipitation (mm/day)\"][var_index]\n",
        "\n",
        "# Compute difference\n",
        "diff = preds_all[:, var_index] - trues_all[:, var_index]\n",
        "\n",
        "# Number of frames (limit for Colab speed)\n",
        "frames = min(len(diff), 120)  # animate first 10 years or so\n",
        "\n",
        "# Create figure\n",
        "fig = plt.figure(figsize=(12, 5))\n",
        "proj = ccrs.PlateCarree()\n",
        "\n",
        "# Axes: Actual, Predicted, Difference\n",
        "ax1 = plt.subplot(1, 3, 1, projection=proj)\n",
        "ax2 = plt.subplot(1, 3, 2, projection=proj)\n",
        "ax3 = plt.subplot(1, 3, 3, projection=proj)\n",
        "\n",
        "# Initialize plots\n",
        "im1 = ax1.pcolormesh(lon2d, lat2d, trues_all[0, var_index], cmap=\"coolwarm\", transform=proj)\n",
        "im2 = ax2.pcolormesh(lon2d, lat2d, preds_all[0, var_index], cmap=\"coolwarm\", transform=proj)\n",
        "im3 = ax3.pcolormesh(lon2d, lat2d, diff[0], cmap=\"bwr\", transform=proj)\n",
        "\n",
        "# Coastlines and titles\n",
        "for ax, title in zip([ax1, ax2, ax3],\n",
        "                     [f\"Actual {var_name}\",\n",
        "                      f\"Predicted {var_name}\",\n",
        "                      \"Predicted ‚àí Actual\"]):\n",
        "    ax.coastlines()\n",
        "    ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
        "    ax.set_global()\n",
        "    ax.set_title(title, fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Update function for animation\n",
        "def update(frame):\n",
        "    im1.set_array(trues_all[frame, var_index].ravel())\n",
        "    im2.set_array(preds_all[frame, var_index].ravel())\n",
        "    im3.set_array(diff[frame].ravel())\n",
        "    fig.suptitle(f\"{var_name} ‚Äî Month #{frame+1}\", fontsize=12)\n",
        "    return [im1, im2, im3]\n",
        "\n",
        "# Create animation\n",
        "ani = animation.FuncAnimation(fig, update, frames=frames, interval=200, blit=False)\n",
        "\n",
        "# Display animation inline (works on Colab)\n",
        "from IPython.display import HTML\n",
        "HTML(ani.to_jshtml())\n"
      ],
      "metadata": {
        "id": "DEvZoXJ3I1G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HtCvlrTbI4gw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}